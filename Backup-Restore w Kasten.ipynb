{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0795ce20",
   "metadata": {},
   "source": [
    "# Backup - Restore with Kasten (a Veeam Company)\n",
    "created by Stephan.Koch@hpe.com\n",
    "\n",
    "used best of breed components\n",
    "- from SuSE/Rancher: Operating System and Kubernetes Distro\n",
    "- from IBM/Red Hat: Automation Engine: Ansible\n",
    "- from VMware: Hypervisor, Cloud Provider and CSI\n",
    "- from Veeam/Kasten: Backup Software\n",
    "- from Microsoft: Azure Blob Storage\n",
    "- from HPE: Blech and Consultant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60a8dca",
   "metadata": {},
   "source": [
    "## First create an K3S cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c205982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory 'kastendemo': File exists\n",
      "/home/skoch/notebooks/k8s/storage/kastendemo\n",
      "packer_id_rsa\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cd ~/notebooks/k8s/storage/\n",
    "rm -rf kastendemo/*yml kastendemo/.inv* kastendemo/node-token kastendemo/vsphere* kastendemo/k3s*\n",
    "mkdir kastendemo\n",
    "cd kastendemo\n",
    "pwd\n",
    "ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9596a6fd",
   "metadata": {},
   "source": [
    "#### create VMs with OS Suse Linux Micro 5.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fdd42941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PLAY [localhost] ***************************************************************\n",
      "\n",
      "TASK [Clone the template] ******************************************************\n",
      "\u001b[0;32mok: [localhost -> localhost] => (item=50)\u001b[0m\n",
      "\u001b[0;32mok: [localhost -> localhost] => (item=51)\u001b[0m\n",
      "\u001b[0;32mok: [localhost -> localhost] => (item=52)\u001b[0m\n",
      "\n",
      "TASK [Creating hosts file for step 2] ******************************************\n",
      "\u001b[0;33mchanged: [localhost]\u001b[0m\n",
      "\n",
      "TASK [Add all nodes] ***********************************************************\n",
      "\u001b[0;33mchanged: [localhost] => (item=51)\u001b[0m\n",
      "\u001b[0;33mchanged: [localhost] => (item=52)\u001b[0m\n",
      "\n",
      "PLAY RECAP *********************************************************************\n",
      "\u001b[0;33mlocalhost\u001b[0m                  : \u001b[0;32mok=3   \u001b[0m \u001b[0;33mchanged=2   \u001b[0m unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cd ~/notebooks/k8s/storage/kastendemo\n",
    "export ANSIBLE_VAULT_PASSWORD_FILE=~/notebooks/k8s/.vault_password_file\n",
    "cat << 'EOF' > .create_vms.yml \n",
    "---\n",
    "- hosts: localhost\n",
    "  gather_facts: no\n",
    "\n",
    "\n",
    "  vars:\n",
    "    ip_addr: \"50\"\n",
    "    amount: \"3\"\n",
    "\n",
    "    vcenter_pass: !vault |\n",
    "        $ANSIBLE_VAULT;1.1;AES256\n",
    "        65363864613935346332643061326331373330656238356631373661393266633665383839353366\n",
    "        3365663565626136636430353431316433636535336330640a346536313330656235636364663637\n",
    "        34333634313939393266666261383835353266373865386632626631666463366535346563396138\n",
    "        3866356538623064380a643830653330653530636137616537636131636631313565303236623839\n",
    "        3063\n",
    "    vcenter_server: \"vc.container.demo.local\"\n",
    "    vcenter_user: \"skoch@demo.local\"\n",
    "    datacenter_name: \"ctcbbn\"\n",
    "    cluster_name: \"Cluster\"\n",
    "    template_name: \"template-sle-micro5-base\"\n",
    "    prefix_ip: \"10.1.35\"\n",
    "    endip: \"{{ ip_addr|int + amount|int -1 }}\"\n",
    "\n",
    "  tasks:\n",
    "    - name: Clone the template\n",
    "      community.vmware.vmware_guest:\n",
    "        hostname: \"{{ vcenter_server }}\"\n",
    "        username: \"{{ vcenter_user }}\"\n",
    "        password: \"{{ vcenter_pass }}\"\n",
    "        validate_certs: False\n",
    "        name: \"k3s-{{ item }}\"\n",
    "        template: \"{{ template_name }}\"\n",
    "        datacenter: \"{{ datacenter_name }}\"\n",
    "        folder: /k3sdemo\n",
    "        cluster: \"{{ cluster_name }}\"\n",
    "        datastore: \"DS3\"\n",
    "        hardware:\n",
    "          memory_mb: 2048\n",
    "          num_cpus: 1\n",
    "        networks:\n",
    "        - name: DPortGroup35\n",
    "          connected: yes\n",
    "          start_connected: yes\n",
    "          ip: \"{{ prefix_ip }}.{{ item }}\"\n",
    "          netmask: 255.255.255.0\n",
    "          gateway: 10.1.35.1\n",
    "          type: static\n",
    "          dns_servers: 10.1.20.5\n",
    "        disk:\n",
    "          - autoselect_datastore: no\n",
    "            datastore: \"DS3\"\n",
    "            size_gb: 30\n",
    "            type: thin\n",
    "        customization:\n",
    "          hostname: \"k3s-{{ item }}\"\n",
    "          domain: container.demo.local\n",
    "          dns_servers:\n",
    "          - 10.1.20.5\n",
    "          - 10.1.20.6\n",
    "        state: poweredon\n",
    "        wait_for_ip_address: no\n",
    "      with_sequence: start={{ip_addr}} end={{endip}} stride=1\n",
    "      delegate_to: localhost\n",
    "\n",
    "    - name: Creating hosts file for step 2\n",
    "      copy:\n",
    "        dest: \"~/notebooks/k8s/storage/kastendemo/.inventory1\"\n",
    "        content: |\n",
    "          [master]\n",
    "          {{ prefix_ip }}.{{ip_addr}}\n",
    "\n",
    "          [nodes]\n",
    "\n",
    "    - name: Add all nodes\n",
    "      ansible.builtin.lineinfile:\n",
    "        path: \"~/notebooks/k8s/storage/kastendemo/.inventory1\"\n",
    "        line: \"{{ prefix_ip }}.{{ item }}\"\n",
    "        create: yes\n",
    "      with_sequence: start={{ip_addr|int + 1}} end={{endip}} stride=1\n",
    "EOF\n",
    "ansible-playbook .create_vms.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b0a3f",
   "metadata": {},
   "source": [
    "#### create K3S cluster on above VMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71cbc40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Permanently added '10.1.35.52' (ECDSA) to the list of known hosts.\n",
      "Thu Apr  8 12:33:06 UTC 2021\n"
     ]
    }
   ],
   "source": [
    "#check if up\n",
    "ssh -o StrictHostKeyChecking=no -i packer_id_rsa bot@10.1.35.52 date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2cd5d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PLAY [all] *********************************************************************\n",
      "\n",
      "TASK [Wait for port ssh to become open on the host] ****************************\n",
      "\u001b[1;35m[WARNING]: Platform linux on host 10.1.35.50 is using the discovered Python\u001b[0m\n",
      "\u001b[1;35minterpreter at /usr/bin/python3.6, but future installation of another Python\u001b[0m\n",
      "\u001b[1;35minterpreter could change the meaning of that path. See https://docs.ansible.com\u001b[0m\n",
      "\u001b[1;35m/ansible/2.10/reference_appendices/interpreter_discovery.html for more\u001b[0m\n",
      "\u001b[1;35minformation.\u001b[0m\n",
      "\u001b[0;32mok: [10.1.35.50]\u001b[0m\n",
      "\u001b[1;35m[WARNING]: Platform linux on host 10.1.35.52 is using the discovered Python\u001b[0m\n",
      "\u001b[1;35minterpreter at /usr/bin/python3.6, but future installation of another Python\u001b[0m\n",
      "\u001b[1;35minterpreter could change the meaning of that path. See https://docs.ansible.com\u001b[0m\n",
      "\u001b[1;35m/ansible/2.10/reference_appendices/interpreter_discovery.html for more\u001b[0m\n",
      "\u001b[1;35minformation.\u001b[0m\n",
      "\u001b[0;32mok: [10.1.35.52]\u001b[0m\n",
      "\u001b[1;35m[WARNING]: Platform linux on host 10.1.35.51 is using the discovered Python\u001b[0m\n",
      "\u001b[1;35minterpreter at /usr/bin/python3.6, but future installation of another Python\u001b[0m\n",
      "\u001b[1;35minterpreter could change the meaning of that path. See https://docs.ansible.com\u001b[0m\n",
      "\u001b[1;35m/ansible/2.10/reference_appendices/interpreter_discovery.html for more\u001b[0m\n",
      "\u001b[1;35minformation.\u001b[0m\n",
      "\u001b[0;32mok: [10.1.35.51]\u001b[0m\n",
      "\n",
      "PLAY [master] ******************************************************************\n",
      "\n",
      "TASK [install k3s on master node] **********************************************\n",
      "\u001b[0;33mchanged: [10.1.35.50]\u001b[0m\n",
      "\n",
      "TASK [fetch the server token] **************************************************\n",
      "\u001b[0;33mchanged: [10.1.35.50]\u001b[0m\n",
      "\n",
      "PLAY [nodes] *******************************************************************\n",
      "\n",
      "TASK [set_fact] ****************************************************************\n",
      "\u001b[0;32mok: [10.1.35.51] => (item=10.1.35.50)\u001b[0m\n",
      "\u001b[0;32mok: [10.1.35.52] => (item=10.1.35.50)\u001b[0m\n",
      "\n",
      "TASK [install k3s on nodes] ****************************************************\n",
      "\u001b[0;33mchanged: [10.1.35.51]\u001b[0m\n",
      "\u001b[0;33mchanged: [10.1.35.52]\u001b[0m\n",
      "\n",
      "PLAY [master] ******************************************************************\n",
      "\n",
      "TASK [kubectl get nodes] *******************************************************\n",
      "\u001b[0;33mchanged: [10.1.35.50]\u001b[0m\n",
      "\n",
      "TASK [debug] *******************************************************************\n",
      "\u001b[0;32mok: [10.1.35.50] => {\u001b[0m\n",
      "\u001b[0;32m    \"msg\": [\u001b[0m\n",
      "\u001b[0;32m        \"NAME     STATUS     ROLES                  AGE   VERSION\",\u001b[0m\n",
      "\u001b[0;32m        \"k3s-50   NotReady   control-plane,master   6s    v1.20.5+k3s1\"\u001b[0m\n",
      "\u001b[0;32m    ]\u001b[0m\n",
      "\u001b[0;32m}\u001b[0m\n",
      "\n",
      "PLAY RECAP *********************************************************************\n",
      "\u001b[0;33m10.1.35.50\u001b[0m                 : \u001b[0;32mok=5   \u001b[0m \u001b[0;33mchanged=3   \u001b[0m unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n",
      "\u001b[0;33m10.1.35.51\u001b[0m                 : \u001b[0;32mok=3   \u001b[0m \u001b[0;33mchanged=1   \u001b[0m unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n",
      "\u001b[0;33m10.1.35.52\u001b[0m                 : \u001b[0;32mok=3   \u001b[0m \u001b[0;33mchanged=1   \u001b[0m unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' > .create_K3S.yml \n",
    "\n",
    "- hosts: all\n",
    "  gather_facts: no\n",
    "  remote_user: bot\n",
    "  vars:\n",
    "    ansible_ssh_private_key_file: ./packer_id_rsa\n",
    "    ansible_host_key_checking: false\n",
    "  tasks:\n",
    "  - name: Wait for port ssh to become open on the host\n",
    "    wait_for:\n",
    "      port: 22\n",
    "      delay: 10\n",
    "\n",
    "- hosts: master\n",
    "  gather_facts: no\n",
    "  remote_user: bot\n",
    "  become: yes\n",
    "  become_method: sudo\n",
    "  vars:\n",
    "    ansible_ssh_private_key_file: ./packer_id_rsa\n",
    "    ansible_host_key_checking: false\n",
    "\n",
    "\n",
    "# use disable cloud provider for be able to set ProviderID for out-of-tree vsphere-CSI\n",
    "  tasks:\n",
    "    - name: install k3s on master node\n",
    "      shell: \"curl -sfL https://get.k3s.io |  sh -s - --disable-cloud-controller\"\n",
    "      args:\n",
    "        warn: false\n",
    "        creates: /usr/local/bin/k3s-uninstall.sh\n",
    "\n",
    "# Retrieve the server token and place it here\n",
    "    - name: fetch the server token\n",
    "      fetch:\n",
    "        src: /var/lib/rancher/k3s/server/node-token\n",
    "        dest: \"./node-token\"\n",
    "        flat: yes\n",
    "\n",
    "\n",
    "# install k3s agent on nodes\n",
    "- hosts: nodes\n",
    "  gather_facts: no\n",
    "  remote_user: bot\n",
    "  become: yes\n",
    "  become_method: sudo\n",
    "  vars:\n",
    "    ansible_ssh_private_key_file: packer_id_rsa\n",
    "    file: .inventory1\n",
    "  tasks:\n",
    "    - set_fact:\n",
    "        k3s_token: \"{{ lookup('file','./node-token')  }}\"\n",
    "        k3s_url: \"https://{{item}}:6443\"\n",
    "      with_lines: cat  {{ file }} | head -2 | tail -1\n",
    "        #k3s_url: \"{{ k3s_url }}\"\n",
    "    - name: install k3s on nodes\n",
    "      shell: \"curl -sfL https://get.k3s.io | K3S_URL={{ k3s_url }} K3S_TOKEN={{ k3s_token }} sh - \"\n",
    "      args:\n",
    "        warn: false\n",
    "        creates: /usr/local/bin/k3s-agent-uninstall.sh\n",
    "\n",
    "# show results\n",
    "- hosts: master\n",
    "  gather_facts: no\n",
    "  remote_user: bot\n",
    "  become: yes\n",
    "  become_method: sudo\n",
    "\n",
    "  tasks:\n",
    "  - name: kubectl get nodes\n",
    "    shell: \"/usr/local/bin/k3s kubectl get nodes\"\n",
    "    register: kctl\n",
    "\n",
    "  - debug: msg={{ kctl.stdout_lines }}\n",
    "\n",
    "EOF\n",
    "export ANSIBLE_HOST_KEY_CHECKING=False\n",
    "ansible-playbook  -i .inventory1   .create_K3S.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaaf507",
   "metadata": {},
   "source": [
    "#### fetch kubeconfig file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b0f084e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PLAY [master] ******************************************************************\n",
      "\n",
      "TASK [fetch the server token] **************************************************\n",
      "\u001b[0;33mchanged: [10.1.35.50]\u001b[0m\n",
      "\n",
      "TASK [set_fact] ****************************************************************\n",
      "\u001b[0;32mok: [10.1.35.50] => (item=10.1.35.50)\u001b[0m\n",
      "\n",
      "TASK [replace 127.0.0.1 with master ip] ****************************************\n",
      "\u001b[0;33mchanged: [10.1.35.50]\u001b[0m\n",
      "\n",
      "PLAY RECAP *********************************************************************\n",
      "\u001b[0;33m10.1.35.50\u001b[0m                 : \u001b[0;32mok=3   \u001b[0m \u001b[0;33mchanged=2   \u001b[0m unreachable=0    failed=0    skipped=0    rescued=0    ignored=0   \n",
      "\n",
      "NAME     STATUS   ROLES                  AGE   VERSION\n",
      "k3s-50   Ready    control-plane,master   45s   v1.20.5+k3s1\n",
      "k3s-51   Ready    <none>                 32s   v1.20.5+k3s1\n",
      "k3s-52   Ready    <none>                 32s   v1.20.5+k3s1\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' > .fetch_k8sconfig.yml \n",
    "- hosts: master\n",
    "  gather_facts: no\n",
    "  remote_user: bot\n",
    "  become: yes\n",
    "  become_method: sudo\n",
    "  vars:\n",
    "    ansible_ssh_private_key_file: ./packer_id_rsa\n",
    "    ansible_host_key_checking: false\n",
    "    file: .inventory1\n",
    "\n",
    "  tasks:\n",
    "# Retrieve the server token and place it here\n",
    "    - name: fetch the server token\n",
    "      ansible.builtin.fetch:\n",
    "        src: /etc/rancher/k3s/k3s.yaml\n",
    "        dest: \"./k3s-kubeconfig\"\n",
    "        flat: yes\n",
    "\n",
    "        \n",
    "    - set_fact:\n",
    "        master: \"{{item}}\"\n",
    "      with_lines: cat  {{ file }} | head -2 | tail -1\n",
    "      \n",
    "    - name: replace 127.0.0.1 with master ip\n",
    "      replace:\n",
    "        path:  k3s-kubeconfig \n",
    "        regexp: '127.0.0.1'\n",
    "        replace: '{{ master }}'\n",
    "        backup: no  \n",
    "      delegate_to: localhost  \n",
    "        \n",
    "\n",
    "EOF\n",
    "ansible-playbook  -i .inventory1   .fetch_k8sconfig.yml\n",
    "\n",
    "chmod 600 k3s-kubeconfig\n",
    "export KUBECONFIG=$PWD/k3s-kubeconfig\n",
    "kubectl get nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "767f0124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME     STATUS   ROLES                  AGE   VERSION\n",
      "k3s-50   Ready    control-plane,master   54s   v1.20.5+k3s1\n",
      "k3s-51   Ready    <none>                 41s   v1.20.5+k3s1\n",
      "k3s-52   Ready    <none>                 41s   v1.20.5+k3s1\n"
     ]
    }
   ],
   "source": [
    "kubectl get no"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9eecd",
   "metadata": {},
   "source": [
    "## Install vSphere- Cloud Provider and Container Storage Interface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1af3ccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "#ProviderID should NOT be set; k8s only allow the change from \"\" \n",
    "kubectl describe node| grep -i ProviderID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548d37c6",
   "metadata": {},
   "source": [
    "##### Update ProviderIDs in K8S and set disk.enableUUID=1 for VMs\n",
    "On a machine with govc, go jq, and kubectl\n",
    "- https://github.com/vmware/govmomi/tree/master/govc\n",
    "- govc is a vSphere CLI built on top of govmomi.\n",
    "- govmomi: Go library for the VMware vSphere API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c9f91d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching k3s-52 with UUID:421ACAE7-F241-FAFF-7276-6B78AA9F8BC1\n",
      "node/k3s-52 patched\n",
      "Patching k3s-51 with UUID:421AD3BE-231E-B7CB-B29B-43286FA779A1\n",
      "node/k3s-51 patched\n",
      "Patching k3s-50 with UUID:421A6F75-B095-FC0F-1F37-B91FB14ED18A\n",
      "node/k3s-50 patched\n"
     ]
    }
   ],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "export GOVC_USERNAME='skoch@demo.local'\n",
    "export GOVC_INSECURE=1\n",
    "export GOVC_PASSWORD=$(echo \"UmF0aW5nZW4uMTIzCg==\"|base64 -d)\n",
    "export GOVC_URL='vc.container.demo.local'\n",
    "DATACENTER='ctcbbn'\n",
    "FOLDER='k3sdemo'\n",
    "# In my case I'm using a prefix for the VM's, so grep'ing is necessary.\n",
    "# You can remove it if the folder you are using only contains the machines you need.\n",
    "VM_PREFIX='/k3s-'\n",
    "IFS=$'\\n'\n",
    "for vm in $(govc ls \"/$DATACENTER/vm/$FOLDER\" | grep $VM_PREFIX); do\n",
    "  MACHINE_INFO=$(govc vm.info -json -dc=$DATACENTER -vm.ipath=\"/$vm\" -e=true)\n",
    "  # My VMs are created on vmware with upper case names, so I need to edit the names with awk\n",
    "  VM_NAME=$(jq -r ' .VirtualMachines[] | .Name' <<< $MACHINE_INFO | awk '{print tolower($0)}')\n",
    "  # UUIDs come in lowercase, upper case then\n",
    "  VM_UUID=$( jq -r ' .VirtualMachines[] | .Config.Uuid' <<< $MACHINE_INFO | awk '{print toupper($0)}')\n",
    "  echo \"Patching $VM_NAME with UUID:$VM_UUID\"\n",
    "  # This is done using dry-run to avoid possible mistakes, remove when you are confident you got everything right.\n",
    "  kubectl patch node $VM_NAME -p \"{\\\"spec\\\":{\\\"providerID\\\":\\\"vsphere://$VM_UUID\\\"}}\"\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a69d509",
   "metadata": {},
   "source": [
    "####executed externally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c7ebcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;31m\u001b[KProviderID\u001b[m\u001b[K:                   vsphere://421ACAE7-F241-FAFF-7276-6B78AA9F8BC1\n",
      "\u001b[01;31m\u001b[KProviderID\u001b[m\u001b[K:                   vsphere://421AD3BE-231E-B7CB-B29B-43286FA779A1\n",
      "\u001b[01;31m\u001b[KProviderID\u001b[m\u001b[K:                   vsphere://421A6F75-B095-FC0F-1F37-B91FB14ED18A\n"
     ]
    }
   ],
   "source": [
    "kubectl describe node| grep -i ProviderID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e69e84d",
   "metadata": {},
   "source": [
    "have to set disk.enableUUID=1 for all vms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1ab87b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patching k3s-52\n",
      "Patching k3s-51\n",
      "Patching k3s-50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for vm in $(govc ls \"/$DATACENTER/vm/$FOLDER\" | grep $VM_PREFIX); do\n",
    "    MACHINE_INFO=$(govc vm.info -json -dc=$DATACENTER -vm.ipath=\"/$vm\" -e=true)\n",
    "    VM_NAME=$(jq -r ' .VirtualMachines[] | .Name' <<< $MACHINE_INFO | awk '{print tolower($0)}')\n",
    "    echo \"Patching $VM_NAME\"\n",
    "    govc vm.change -e=\"disk.enableUUID=1\" -vm=$VM_NAME\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39e6730",
   "metadata": {},
   "source": [
    "#### Install CP and CSI with helm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3eb82220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'vsphere-cpi-csi-helm'...\n",
      "remote: Enumerating objects: 87, done.\u001b[K\n",
      "remote: Counting objects: 100% (87/87), done.\u001b[K\n",
      "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
      "remote: Total 165 (delta 35), reused 50 (delta 18), pack-reused 78\u001b[K\n",
      "Receiving objects: 100% (165/165), 64.20 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (63/63), done.\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/stefanvangastel/vsphere-cpi-csi-helm\n",
    "git clone https://github.com/stefanvangastel/vsphere-cpi-csi-helm.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a45e9cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: vsphere-cpi-csi\n",
      "LAST DEPLOYED: Thu Apr  8 14:42:06 2021\n",
      "NAMESPACE: kube-system\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n"
     ]
    }
   ],
   "source": [
    "cd vsphere-cpi-csi-helm\n",
    "\n",
    "helm install vsphere-cpi-csi \\\n",
    "     --namespace kube-system \\\n",
    "     ./charts/vsphere-cpi-csi/v2.1.0 \\\n",
    "     --set vcenter.host=vc.container.demo.local \\\n",
    "     --set vcenter.username=skoch@demo.local \\\n",
    "     --set vcenter.password=$(echo \"UmF0aW5nZW4uMTIzCg==\"|base64 -d) \\\n",
    "     --set insecure-flag=true \\\n",
    "     --set vcenter.datacenter=ctcbbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "85144b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                      READY   STATUS              RESTARTS   AGE\n",
      "coredns-854c77959c-xlh4k                  1/1     Running             0          97s\n",
      "local-path-provisioner-5ff76fc89d-6gwpt   1/1     Running             0          97s\n",
      "metrics-server-86cbb8457f-rlrss           1/1     Running             0          97s\n",
      "helm-install-traefik-pmx79                0/1     Completed           0          97s\n",
      "svclb-traefik-9thf9                       2/2     Running             0          77s\n",
      "svclb-traefik-zvhqx                       2/2     Running             0          77s\n",
      "svclb-traefik-c27rn                       2/2     Running             0          77s\n",
      "traefik-6f9cbd9bd4-nwcrz                  1/1     Running             0          77s\n",
      "vsphere-csi-controller-789b8f4956-rx596   0/6     Pending             0          4s\n",
      "vsphere-csi-node-9tkhb                    0/3     ContainerCreating   0          4s\n",
      "vsphere-csi-node-dfngv                    0/3     ContainerCreating   0          4s\n",
      "vsphere-csi-node-srtr2                    0/3     ContainerCreating   0          4s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pod -n kube-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8038dac",
   "metadata": {},
   "source": [
    "#### patching deployment because K3S label nodes as \"control-plane\" and not \"controlplane\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "63995810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"default\" modified.\n",
      "Active namespace is \"kube-system\".\n",
      "deployment.apps/vsphere-csi-controller patched\n",
      "deployment.apps/vsphere-csi-controller patched\n"
     ]
    }
   ],
   "source": [
    "kubens kube-system\n",
    "kubectl patch deployment vsphere-csi-controller --type=json -p='[{\"op\": \"remove\", \"path\": \"/spec/template/spec/nodeSelector\"}]'\n",
    "kubectl patch --type merge deployment vsphere-csi-controller -p '{ \"spec\": { \"template\": { \"spec\": { \"nodeSelector\": { \"node-role.kubernetes.io/control-plane\": \"true\" } } } } }'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfc2574",
   "metadata": {},
   "source": [
    "delete nodeselector node-role.kubernetes.io/controlplane \"without \"-\"\"\n",
    "via kubectl edit deployment vsphere-csi-controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e06b09db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                      READY   STATUS      RESTARTS   AGE\n",
      "coredns-854c77959c-xlh4k                  1/1     Running     0          2m52s\n",
      "local-path-provisioner-5ff76fc89d-6gwpt   1/1     Running     0          2m52s\n",
      "metrics-server-86cbb8457f-rlrss           1/1     Running     0          2m52s\n",
      "helm-install-traefik-pmx79                0/1     Completed   0          2m52s\n",
      "svclb-traefik-9thf9                       2/2     Running     0          2m32s\n",
      "svclb-traefik-zvhqx                       2/2     Running     0          2m32s\n",
      "svclb-traefik-c27rn                       2/2     Running     0          2m32s\n",
      "traefik-6f9cbd9bd4-nwcrz                  1/1     Running     0          2m32s\n",
      "vsphere-csi-node-dfngv                    3/3     Running     0          79s\n",
      "vsphere-csi-node-9tkhb                    3/3     Running     0          79s\n",
      "vsphere-csi-node-srtr2                    3/3     Running     0          79s\n",
      "vsphere-csi-controller-74c8855867-fjm2r   6/6     Running     0          65s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pod -n kube-system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2accc75",
   "metadata": {},
   "source": [
    "#### check if sc and csidriver is defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a1751589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                PROVISIONER              RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\n",
      "storageclass.storage.k8s.io/local-path (default)    rancher.io/local-path    Delete          WaitForFirstConsumer   false                  2m45s\n",
      "storageclass.storage.k8s.io/vsphere-csi (default)   csi.vsphere.vmware.com   Delete          Immediate              false                  60s\n",
      "\n",
      "NAME                                              ATTACHREQUIRED   PODINFOONMOUNT   MODES        AGE\n",
      "csidriver.storage.k8s.io/csi.vsphere.vmware.com   true             false            Persistent   60s\n"
     ]
    }
   ],
   "source": [
    "kubectl get sc,csidrivers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86d12d",
   "metadata": {},
   "source": [
    "#### check if csi working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c0229795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolumeclaim/csi-pvc1 created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "---\n",
    "kind: PersistentVolumeClaim\n",
    "apiVersion: v1\n",
    "metadata:\n",
    "  name: csi-pvc1\n",
    "  labels:\n",
    "    cluster: ocp46\n",
    "  annotations:\n",
    "    volume.beta.kubernetes.io/storage-class: vsphere-csi\n",
    "spec:\n",
    "  accessModes:\n",
    "  - ReadWriteOnce\n",
    "  resources:\n",
    "    requests:\n",
    "      storage: 1400Mi\n",
    "EOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99f15ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME       STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "csi-pvc1   Bound    pvc-2a3f4465-a1b0-41b5-a367-99f89d288999   2Gi        RWO            vsphere-csi    4s\n"
     ]
    }
   ],
   "source": [
    "kubectl get pvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cd335f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "persistentvolumeclaim \"csi-pvc1\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete pvc/csi-pvc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e90fb4",
   "metadata": {},
   "source": [
    "## Install Kasten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9072c508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                    PROVISIONER              RECLAIMPOLICY   VOLUMEBINDINGMODE      ALLOWVOLUMEEXPANSION   AGE\n",
      "local-path (default)    rancher.io/local-path    Delete          WaitForFirstConsumer   false                  3m11s\n",
      "vsphere-csi (default)   csi.vsphere.vmware.com   Delete          Immediate              false                  86s\n"
     ]
    }
   ],
   "source": [
    "kubectl get sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fda013d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"kasten\" has been added to your repositories\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"hpe-storage\" chart repository\n",
      "...Successfully got an update from the \"kasten\" chart repository\n",
      "...Successfully got an update from the \"cormachogan\" chart repository\n",
      "...Successfully got an update from the \"halkeye\" chart repository\n",
      "...Successfully got an update from the \"harbor\" chart repository\n",
      "...Unable to get an update from the \"stable\" chart repository (https://kubernetes-charts.storage.googleapis.com):\n",
      "\tfailed to fetch https://kubernetes-charts.storage.googleapis.com/index.yaml : 403 Forbidden\n",
      "...Successfully got an update from the \"bitnami\" chart repository\n",
      "Update Complete. ⎈ Happy Helming!⎈ \n"
     ]
    }
   ],
   "source": [
    "helm repo add kasten https://charts.kasten.io/\n",
    "helm repo update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7b17e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/kasten-io created\n",
      "NAME: k10\n",
      "LAST DEPLOYED: Thu Apr  8 14:43:44 2021\n",
      "NAMESPACE: kasten-io\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "Thank you for installing Kasten’s K10 Data Management Platform!\n",
      "\n",
      "Documentation can be found at https://docs.kasten.io/.\n",
      "\n",
      "How to access the K10 Dashboard:\n",
      "\n",
      "\n",
      "\n",
      "The K10 dashboard is not exposed externally. To establish a connection to it use the following `kubectl` command:\n",
      "\n",
      "`kubectl --namespace kasten-io port-forward service/gateway 8080:8000`\n",
      "\n",
      "The Kasten dashboard will be available at: `http://127.0.0.1:8080/k10/#/`\n"
     ]
    }
   ],
   "source": [
    "kubectl create ns kasten-io\n",
    "helm install k10 kasten/k10 --namespace=kasten-io --set global.persistence.storageClass=vsphere-csi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e93f77bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"default\" modified.\n",
      "NAME                                      READY   STATUS    RESTARTS   AGE\n",
      "pod/dashboardbff-svc-6556497b9-r8wl2      1/1     Running   0          118s\n",
      "pod/logging-svc-d4c959f77-ksgf9           1/1     Running   0          116s\n",
      "pod/jobs-svc-5c5fbb6ddb-k54vb             1/1     Running   0          118s\n",
      "pod/state-svc-6cd69b76b9-5rs7x            1/1     Running   0          116s\n",
      "pod/auth-svc-89779cf75-6qjq4              1/1     Running   0          116s\n",
      "pod/aggregatedapis-svc-65cdccd9bd-l988b   1/1     Running   0          116s\n",
      "pod/config-svc-6b4dd8b699-52t4j           1/1     Running   0          116s\n",
      "pod/crypto-svc-84454c9c7c-kz6w4           1/1     Running   0          115s\n",
      "pod/metering-svc-6fd6f86cb-cfm48          1/1     Running   0          116s\n",
      "pod/frontend-svc-6f9d98bc9c-vxz8h         1/1     Running   0          117s\n",
      "pod/executor-svc-844cfdc565-2v5rq         2/2     Running   0          118s\n",
      "pod/kanister-svc-6d95cbcd5-hpdhm          1/1     Running   0          118s\n",
      "pod/prometheus-server-78b94b85fb-bjkw4    2/2     Running   0          116s\n",
      "pod/executor-svc-844cfdc565-9vdfg         2/2     Running   0          118s\n",
      "pod/executor-svc-844cfdc565-dxnfg         2/2     Running   0          118s\n",
      "pod/catalog-svc-74cc78b8d7-sw6jh          2/2     Running   0          116s\n",
      "pod/gateway-b98dd4dcd-hmzlm               1/1     Running   0          118s\n",
      "\n",
      "NAME                                      STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "persistentvolumeclaim/prometheus-server   Bound    pvc-3e3389f8-811e-41f0-99f1-90575da7c9d8   8Gi        RWO            vsphere-csi    119s\n",
      "persistentvolumeclaim/catalog-pv-claim    Bound    pvc-686031b3-daed-45e0-bee6-119d86559ae6   20Gi       RWO            vsphere-csi    119s\n",
      "persistentvolumeclaim/metering-pv-claim   Bound    pvc-31fda7aa-60e6-40fc-908e-7f4bb2cce95f   2Gi        RWO            vsphere-csi    119s\n",
      "persistentvolumeclaim/jobs-pv-claim       Bound    pvc-aba08032-813e-4262-a51d-4799161599eb   20Gi       RWO            vsphere-csi    119s\n",
      "persistentvolumeclaim/logging-pv-claim    Bound    pvc-58e124c0-e475-4ffd-b802-87cb7f3abebc   20Gi       RWO            vsphere-csi    119s\n"
     ]
    }
   ],
   "source": [
    "kubectl config set-context --current --namespace=kasten-io\n",
    "kubectl get pod,pvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1616263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on master node as root\n",
    "#k3s kubectl --namespace kasten-io port-forward --address 0.0.0.0 service/gateway 8080:8000 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f7d788",
   "metadata": {},
   "source": [
    "![title](pictures/Welcome.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032d0c9c",
   "metadata": {},
   "source": [
    "#### define external Storage Location (in my Case Azure Blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1734c274",
   "metadata": {},
   "source": [
    "![AZBlob](pictures/Backup-Destination-AZ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2469c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: config.kio.kasten.io/v1alpha1\n",
      "kind: Profile\n",
      "metadata:\n",
      "  name: az-stephan\n",
      "  namespace: kasten-io\n",
      "spec:\n",
      "  locationSpec:\n",
      "    credential:\n",
      "      secret:\n",
      "        apiVersion: v1\n",
      "        kind: secret\n",
      "        name: k10secret-bpvrb\n",
      "        namespace: kasten-io\n",
      "      secretType: AzStorageAccount\n",
      "    objectStore:\n",
      "      name: kasten-demo\n",
      "      objectStoreType: AZ\n",
      "      path: k10/9687a54f-87ed-4b38-82ca-d88eac0f965e/migration\n",
      "      pathType: Directory\n",
      "      region: West Europe\n",
      "    type: ObjectStore\n",
      "  type: Location\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl get profile az-stephan -o yaml| kubectl neat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc8c656",
   "metadata": {},
   "source": [
    "#### define an Infrastructure Provider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc89d96d",
   "metadata": {},
   "source": [
    "![InfraProvider](pictures/Infra-Provider.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1610b7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: config.kio.kasten.io/v1alpha1\n",
      "kind: Profile\n",
      "metadata:\n",
      "  name: vsphere-ctc\n",
      "  namespace: kasten-io\n",
      "spec:\n",
      "  infra:\n",
      "    credential:\n",
      "      secret:\n",
      "        apiVersion: v1\n",
      "        kind: secret\n",
      "        name: k10secret-qp46q\n",
      "        namespace: kasten-io\n",
      "      secretType: VSphereKey\n",
      "    type: VSphere\n",
      "    vsphere:\n",
      "      serverAddress: vc.container.demo.local\n",
      "  type: Infra\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl get profile vsphere-ctc -o yaml| kubectl neat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35378b8",
   "metadata": {},
   "source": [
    "#### enable K10 DR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cfc2f7",
   "metadata": {},
   "source": [
    "![title](pictures/Enable-K10-DR.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2c4cb835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "data:\n",
      "  key: a2FzdGVuMXNjODhs\n",
      "kind: Secret\n",
      "metadata:\n",
      "  name: k10-dr-secret\n",
      "  namespace: kasten-io\n",
      "type: Opaque\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl get secret k10-dr-secret  -o yaml| kubectl neat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b25dcc5",
   "metadata": {},
   "source": [
    "![title](pictures/Enable-K10-DR-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5e1eba2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "backupactions                                  actions.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io          true         BackupAction\n",
      "backupclusteractions                           actions.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io          false        BackupClusterAction\n",
      "exportactions                                  actions.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io          true         ExportAction\n",
      "importactions                                  actions.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io          true         ImportAction\n",
      "restoreactions                                 actions.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io          true         RestoreAction\n",
      "restoreclusteractions                          actions.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io          false        RestoreClusterAction\n",
      "retireactions                                  actions.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io          false        RetireAction\n",
      "runactions                                     actions.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io          false        RunAction\n",
      "applications                                   apps.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io             true         Application\n",
      "clusterrestorepoints                           apps.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io             false        ClusterRestorePoint\n",
      "restorepointcontents                           apps.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io             false        RestorePointContent\n",
      "restorepoints                                  apps.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io             true         RestorePoint\n",
      "k10clusterrolebindings                         auth.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io             true         K10ClusterRoleBinding\n",
      "k10clusterroles                                auth.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io             true         K10ClusterRole\n",
      "policies                                       config.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io           true         Policy\n",
      "profiles                                       config.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io           true         Profile\n",
      "bootstraps                                     dist.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io             true         Bootstrap\n",
      "clusters                                       dist.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io             true         Cluster\n",
      "distributions                                  dist.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io             true         Distribution\n",
      "passkeys                                       vault.kio.\u001b[01;31m\u001b[Kkasten\u001b[m\u001b[K.io            false        Passkey\n"
     ]
    }
   ],
   "source": [
    "kubectl api-resources --verbs=list | grep -i kasten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eaf80bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                            TYPE                                  DATA   AGE\n",
      "default-token-x69qn             kubernetes.io/service-account-token   3      5m41s\n",
      "kopia-tls-cert                  Opaque                                1      5m40s\n",
      "k10-trial-license               Opaque                                1      5m40s\n",
      "kopia-tls-key                   Opaque                                1      5m40s\n",
      "k10-license                     Opaque                                1      5m40s\n",
      "prometheus-server-token-lqmdd   kubernetes.io/service-account-token   3      5m40s\n",
      "k10-k10-token-w2c5j             kubernetes.io/service-account-token   3      5m40s\n",
      "sh.helm.release.v1.k10.v1       helm.sh/release.v1                    1      5m40s\n",
      "k10-cluster-passphrase          Opaque                                1      4m16s\n",
      "k10secret-7qqtf                 Opaque                                2      2m2s\n",
      "k10secret-gz7x8                 Opaque                                2      95s\n",
      "k10-dr-secret                   Opaque                                1      66s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kubectl get secret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7952f41",
   "metadata": {},
   "source": [
    "#### create backup for cluster-scoped resources with export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed45eab0",
   "metadata": {},
   "source": [
    "## for DR purpose save some inmportant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f3c1ded0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "840916bd-40e0-4f19-8dee-631bd857c2ef\n"
     ]
    }
   ],
   "source": [
    " #Extract UUID of the `default` namespace for DR porpuse\n",
    " kubectl get namespace default -ojsonpath=\"{.metadata.uid}{'\\n'}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "be6122fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "data:\n",
      "  key: a2FzdGVuMXNjODhs\n",
      "kind: Secret\n",
      "metadata:\n",
      "  name: k10-dr-secret\n",
      "  namespace: kasten-io\n",
      "type: Opaque\n",
      "\n",
      "---\n",
      "kasten1sc88l"
     ]
    }
   ],
   "source": [
    "kubectl get secret  k10-dr-secret -o yaml --namespace kasten-io |kubectl neat\n",
    "echo \"---\"\n",
    "kubectl get secret  k10-dr-secret -o json --namespace kasten-io | jq -r .data.key|base64 -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c6eb9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME          STATUS\n",
      "az-stephan    Success\n",
      "vsphere-ctc   Success\n"
     ]
    }
   ],
   "source": [
    "kubectl get profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "da6860cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: config.kio.kasten.io/v1alpha1\n",
      "kind: Profile\n",
      "metadata:\n",
      "  name: az-stephan\n",
      "  namespace: kasten-io\n",
      "spec:\n",
      "  locationSpec:\n",
      "    credential:\n",
      "      secret:\n",
      "        apiVersion: v1\n",
      "        kind: secret\n",
      "        name: k10secret-7qqtf\n",
      "        namespace: kasten-io\n",
      "      secretType: AzStorageAccount\n",
      "    objectStore:\n",
      "      name: kasten-demo\n",
      "      objectStoreType: AZ\n",
      "      path: k10/840916bd-40e0-4f19-8dee-631bd857c2ef/migration\n",
      "      pathType: Directory\n",
      "      region: West Europe\n",
      "    type: ObjectStore\n",
      "  type: Location\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl get profile az-stephan -o yaml | kubectl neat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a08135c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: config.kio.kasten.io/v1alpha1\n",
      "kind: Profile\n",
      "metadata:\n",
      "  name: vsphere-ctc\n",
      "  namespace: kasten-io\n",
      "spec:\n",
      "  infra:\n",
      "    credential:\n",
      "      secret:\n",
      "        apiVersion: v1\n",
      "        kind: secret\n",
      "        name: k10secret-gz7x8\n",
      "        namespace: kasten-io\n",
      "      secretType: VSphereKey\n",
      "    type: VSphere\n",
      "    vsphere:\n",
      "      serverAddress: vc.container.demo.local\n",
      "  type: Infra\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl get profile vsphere-ctc -o yaml | kubectl neat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0fcab7",
   "metadata": {},
   "source": [
    "### my backup policies for reference and DR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "04da4441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: v1\n",
      "items:\n",
      "- apiVersion: config.kio.kasten.io/v1alpha1\n",
      "  kind: Policy\n",
      "  metadata:\n",
      "    name: k10-disaster-recovery-policy\n",
      "    namespace: kasten-io\n",
      "  spec:\n",
      "    actions:\n",
      "    - action: backup\n",
      "      backupParameters:\n",
      "        profile:\n",
      "          name: az-stephan\n",
      "          namespace: kasten-io\n",
      "    frequency: '@hourly'\n",
      "    retention:\n",
      "      daily: 1\n",
      "      hourly: 4\n",
      "      monthly: 1\n",
      "      weekly: 1\n",
      "      yearly: 1\n",
      "    selector:\n",
      "      matchExpressions:\n",
      "      - key: k10.kasten.io/appNamespace\n",
      "        operator: In\n",
      "        values:\n",
      "        - kasten-io\n",
      "kind: List\n",
      "metadata:\n",
      "  resourceVersion: \"\"\n",
      "  selfLink: \"\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl get policies -n kasten-io -o yaml| kubectl neat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6093ef",
   "metadata": {},
   "source": [
    "# Install Demo Application Wordpress with MariaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "353e318b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/my-wordpress created\n",
      "Context \"default\" modified.\n"
     ]
    }
   ],
   "source": [
    "kubectl create ns my-wordpress\n",
    "kubectl config set-context --current --namespace=my-wordpress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d730d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"bitnami\" has been added to your repositories\n"
     ]
    }
   ],
   "source": [
    "helm repo add bitnami https://charts.bitnami.com/bitnami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a24a5db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: my-wordpress\n",
      "LAST DEPLOYED: Thu Apr  8 15:30:51 2021\n",
      "NAMESPACE: my-wordpress\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "NOTES:\n",
      "** Please be patient while the chart is being deployed **\n",
      "\n",
      "Your WordPress site can be accessed through the following DNS name from within your cluster:\n",
      "\n",
      "    my-wordpress.my-wordpress.svc.cluster.local (port 80)\n",
      "\n",
      "To access your WordPress site from outside the cluster follow the steps below:\n",
      "\n",
      "1. Get the WordPress URL by running these commands:\n",
      "\n",
      "   export NODE_PORT=$(kubectl get --namespace my-wordpress -o jsonpath=\"{.spec.ports[0].nodePort}\" services my-wordpress)\n",
      "   export NODE_IP=$(kubectl get nodes --namespace my-wordpress -o jsonpath=\"{.items[0].status.addresses[0].address}\")\n",
      "   echo \"WordPress URL: http://$NODE_IP:$NODE_PORT/\"\n",
      "   echo \"WordPress Admin URL: http://$NODE_IP:$NODE_PORT/admin\"\n",
      "\n",
      "2. Open a browser and access WordPress using the obtained URL.\n",
      "\n",
      "3. Login with the following credentials below to see your blog:\n",
      "\n",
      "  echo Username: admin\n",
      "  echo Password: $(kubectl get secret --namespace my-wordpress my-wordpress -o jsonpath=\"{.data.wordpress-password}\" | base64 --decode)\n"
     ]
    }
   ],
   "source": [
    "helm install my-wordpress \\\n",
    "  --set wordpressUsername=admin \\\n",
    "  --set wordpressPassword=password \\\n",
    "  --set mariadb.auth.rootPassword=secretpassword \\\n",
    "  --set mariadb.auth.password=notsosecret \\\n",
    "  --set global.storageClass=vsphere-csi \\\n",
    "  --set service.type=NodePort \\\n",
    "    bitnami/wordpress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "a2be8086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                               READY   STATUS    RESTARTS   AGE\n",
      "pod/my-wordpress-mariadb-0         1/1     Running   0          14m\n",
      "pod/my-wordpress-d887bbd78-dmlhn   1/1     Running   0          14m\n",
      "\n",
      "NAME                           TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)                      AGE\n",
      "service/my-wordpress-mariadb   ClusterIP   10.43.20.91    <none>        3306/TCP                     14m\n",
      "service/my-wordpress           NodePort    10.43.229.92   <none>        80:31195/TCP,443:30983/TCP   14m\n",
      "\n",
      "NAME                           READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "deployment.apps/my-wordpress   1/1     1            1           14m\n",
      "\n",
      "NAME                                     DESIRED   CURRENT   READY   AGE\n",
      "replicaset.apps/my-wordpress-d887bbd78   1         1         1       14m\n",
      "\n",
      "NAME                                    READY   AGE\n",
      "statefulset.apps/my-wordpress-mariadb   1/1     14m\n"
     ]
    }
   ],
   "source": [
    "kubectl get all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e2b3e3e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/regcred created\n"
     ]
    }
   ],
   "source": [
    "# in case of docker limit reached: do an docker login and use the created .docker/config.json for increasing \n",
    "cd ~/notebooks/k8s/storage/kastendemo/\n",
    "kubectl create secret generic regcred \\\n",
    "    --from-file=.dockerconfigjson=config.json \\\n",
    "    --type=kubernetes.io/dockerconfigjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f8131663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                          STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS   AGE\n",
      "my-wordpress                  Bound    pvc-56ca3a54-c7fd-41c9-b157-8e1fac27fc4c   10Gi       RWO            vsphere-csi    15m\n",
      "data-my-wordpress-mariadb-0   Bound    pvc-1050b7dd-e7e9-4f22-97bc-4a4763ca7319   8Gi        RWO            vsphere-csi    15m\n"
     ]
    }
   ],
   "source": [
    "kubectl get pvc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2125f67e",
   "metadata": {},
   "source": [
    "### do some changes on Wordpress\n",
    "\n",
    "login with: http://10.1.35.51:31195/login\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7c02b",
   "metadata": {},
   "source": [
    "#### create Backup in Kasten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d647506",
   "metadata": {},
   "source": [
    "![wordpressBackup](pictures/my-wordpress-backup.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e7dc4435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: config.kio.kasten.io/v1alpha1\n",
      "kind: Policy\n",
      "metadata:\n",
      "  name: my-wordpress-backup\n",
      "  namespace: kasten-io\n",
      "spec:\n",
      "  actions:\n",
      "  - action: backup\n",
      "    backupParameters:\n",
      "      profile:\n",
      "        name: az-stephan\n",
      "        namespace: kasten-io\n",
      "  - action: export\n",
      "    exportParameters:\n",
      "      exportData:\n",
      "        enabled: true\n",
      "      frequency: '@weekly'\n",
      "      migrationToken:\n",
      "        name: my-wordpress-backup-migration-token-q5d6v\n",
      "        namespace: kasten-io\n",
      "      profile:\n",
      "        name: az-stephan\n",
      "        namespace: kasten-io\n",
      "      receiveString: bIzAPpoanmEpnjszvlUynfclRGkuPneFySzSpUwzW6kbL+x7h3SybL+aZuOrkKg6BxfWzKuNGWik9SNd1g6xyGY0+AYfLO+bYbay8eWagcya56Fh53Acb1mo6pHIA70rT4EKuAoOkeJJsuvRtK3Sw0mnMsHTxQIVp1nSIEidip3E0YMIAwLY2mDV6yKCbUs2o+dyYc3z/mkbw1wMLCPKoNq5TDDqQDuzuTIdooWMboUeuIqLcm6OZMYM9aSZxcC4NMiNOayPdZxwSXj2p0gksifK9eKDaujY1AuMQys1W2RnXkTeq2Bwrjafuc3H9t1i1ldiZJhahHEDmcRowHypHfNatpFUeRIT79U5xNG9p7fyw0SEptrdt3tv8xfyw3t7sNHiLJxB3veiH34nn5AfCyl56LCaQhVSTlLeqB7m\n",
      "  frequency: '@weekly'\n",
      "  retention:\n",
      "    monthly: 12\n",
      "    weekly: 4\n",
      "    yearly: 7\n",
      "  selector:\n",
      "    matchExpressions:\n",
      "    - key: k10.kasten.io/appNamespace\n",
      "      operator: In\n",
      "      values:\n",
      "      - my-wordpress\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kubectl get policies my-wordpress-backup -n kasten-io -o yaml| kubectl neat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16ed714",
   "metadata": {},
   "source": [
    "### Be destructive !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "c65d19e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace \"my-wordpress\" deleted\n"
     ]
    }
   ],
   "source": [
    "kubectl delete ns my-wordpress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e52a334e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No resources found in my-wordpress namespace.\n"
     ]
    }
   ],
   "source": [
    "kubectl get all,pvc -n my-wordpress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113974ae",
   "metadata": {},
   "source": [
    "### Restore now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8dbe0f",
   "metadata": {},
   "source": [
    "![wordpressRestore](pictures/Restore-wordpress.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf5275a",
   "metadata": {},
   "source": [
    "##### IF restore through GUI failed\n",
    "(failed with ver 3.0.10 but not with 3.0.11)\n",
    "\n",
    "```ERROR MESSAGES\n",
    "  Job failed to be executed\n",
    " Failed to restore spec artifacts\n",
    " Service \"my-wordpress-mariadb\" is invalid: spec.clusterIPs: Invalid value: []string{\"10.43.124.158\"}: must be empty when clusterIP is empty\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "6e3d7b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    \u001b[01;31m\u001b[KclusterIP\u001b[m\u001b[K: 10.43.62.136\n",
      "    \u001b[01;31m\u001b[KclusterIP\u001b[m\u001b[Ks:\n",
      "    type: \u001b[01;31m\u001b[KClusterIP\u001b[m\u001b[K\n",
      "    \u001b[01;31m\u001b[KclusterIP\u001b[m\u001b[K: 10.43.61.180\n",
      "    \u001b[01;31m\u001b[KclusterIP\u001b[m\u001b[Ks:\n"
     ]
    }
   ],
   "source": [
    "#output after restore!\n",
    "kubectl get svc -o yaml| grep -i clusterip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c098235b",
   "metadata": {},
   "source": [
    "#### either install fresh and do an restore OR define services manually and do the restore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "10492177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/my-wordpress-mariadb created\n",
      "service/my-wordpress created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "apiVersion: v1\n",
    "items:\n",
    "- apiVersion: v1\n",
    "  kind: Service\n",
    "  metadata:\n",
    "    annotations:\n",
    "      meta.helm.sh/release-name: my-wordpress\n",
    "      meta.helm.sh/release-namespace: my-wordpress\n",
    "    labels:\n",
    "      app.kubernetes.io/component: primary\n",
    "      app.kubernetes.io/instance: my-wordpress\n",
    "      app.kubernetes.io/managed-by: Helm\n",
    "      app.kubernetes.io/name: mariadb\n",
    "      helm.sh/chart: mariadb-9.3.6\n",
    "    name: my-wordpress-mariadb\n",
    "    namespace: my-wordpress\n",
    "  spec:\n",
    "    clusterIP: \n",
    "    clusterIPs:\n",
    "    \n",
    "    ports:\n",
    "    - name: mysql\n",
    "      port: 3306\n",
    "      targetPort: mysql\n",
    "    selector:\n",
    "      app.kubernetes.io/component: primary\n",
    "      app.kubernetes.io/instance: my-wordpress\n",
    "      app.kubernetes.io/name: mariadb\n",
    "- apiVersion: v1\n",
    "  kind: Service\n",
    "  metadata:\n",
    "    annotations:\n",
    "      meta.helm.sh/release-name: my-wordpress\n",
    "      meta.helm.sh/release-namespace: my-wordpress\n",
    "    labels:\n",
    "      app.kubernetes.io/instance: my-wordpress\n",
    "      app.kubernetes.io/managed-by: Helm\n",
    "      app.kubernetes.io/name: wordpress\n",
    "      helm.sh/chart: wordpress-10.8.0\n",
    "    name: my-wordpress\n",
    "    namespace: my-wordpress\n",
    "  spec:\n",
    "    clusterIP: \n",
    "    clusterIPs:\n",
    "    \n",
    "    ports:\n",
    "    - name: http\n",
    "      nodePort: 32183\n",
    "      port: 80\n",
    "      targetPort: http\n",
    "    - name: https\n",
    "      nodePort: 31673\n",
    "      port: 443\n",
    "      targetPort: https\n",
    "    selector:\n",
    "      app.kubernetes.io/instance: my-wordpress\n",
    "      app.kubernetes.io/name: wordpress\n",
    "    type: NodePort\n",
    "kind: List\n",
    "metadata:\n",
    "  resourceVersion: \"\"\n",
    "  selfLink: \"\"\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c7189d",
   "metadata": {},
   "source": [
    "##### restore now ....... succeeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "859a5c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                               READY   STATUS    RESTARTS   AGE\n",
      "pod/my-wordpress-mariadb-0         1/1     Running   0          7m51s\n",
      "pod/my-wordpress-d887bbd78-hv4k7   1/1     Running   1          7m51s\n",
      "\n",
      "NAME                           TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE\n",
      "service/my-wordpress-mariadb   ClusterIP   10.43.162.228   <none>        3306/TCP                     7m54s\n",
      "service/my-wordpress           NodePort    10.43.38.112    <none>        80:32665/TCP,443:30314/TCP   7m54s\n",
      "\n",
      "NAME                           READY   UP-TO-DATE   AVAILABLE   AGE\n",
      "deployment.apps/my-wordpress   1/1     1            1           7m51s\n",
      "\n",
      "NAME                                     DESIRED   CURRENT   READY   AGE\n",
      "replicaset.apps/my-wordpress-d887bbd78   1         1         1       7m51s\n",
      "\n",
      "NAME                                    READY   AGE\n",
      "statefulset.apps/my-wordpress-mariadb   1/1     7m52s\n",
      "\n",
      "NAME                                                STATUS   VOLUME                                   CAPACITY      ACCESS MODES   STORAGECLASS   AGE\n",
      "persistentvolumeclaim/my-wordpress                  Bound    kio-c03f4e36987311eba8aa5252376f00fc-1   10737418240   RWO            vsphere-csi    7m52s\n",
      "persistentvolumeclaim/data-my-wordpress-mariadb-0   Bound    kio-c03f4e36987311eba8aa5252376f00fc-0   8589934592    RWO            vsphere-csi    7m52s\n"
     ]
    }
   ],
   "source": [
    "kubectl get all,pvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4431bec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d656d10f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ded52f2",
   "metadata": {},
   "source": [
    "### now be really destructive and delete the whole cluster/VMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ec835e",
   "metadata": {},
   "source": [
    "### reinstall cluster like above, reinstall vsphere cp+csi\n",
    "follow the steps above until installing Kasten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f845857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "49a64f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"kasten\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"kasten\" chart repository\n",
      "...Successfully got an update from the \"bitnami\" chart repository\n",
      "...Successfully got an update from the \"stable\" chart repository\n",
      "Update Complete. ⎈Happy Helming!⎈\n"
     ]
    }
   ],
   "source": [
    "helm repo add kasten https://charts.kasten.io/\n",
    "helm repo update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f20057b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8d99ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "e57352be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/kasten-io created\n",
      "Context \"default\" modified.\n",
      "Active namespace is \"kasten-io\".\n"
     ]
    }
   ],
   "source": [
    "kubectl create ns kasten-io\n",
    "kubens kasten-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "5895e638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (AlreadyExists): namespaces \"kasten-io\" already exists\n",
      "NAME: k10\n",
      "LAST DEPLOYED: Wed Apr  7 15:22:20 2021\n",
      "NAMESPACE: kasten-io\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "NOTES:\n",
      "Thank you for installing Kasten’s K10 Data Management Platform!\n",
      "\n",
      "Documentation can be found at https://docs.kasten.io/.\n",
      "\n",
      "How to access the K10 Dashboard:\n",
      "\n",
      "\n",
      "\n",
      "The K10 dashboard is not exposed externally. To establish a connection to it use the following `kubectl` command:\n",
      "\n",
      "`kubectl --namespace kasten-io port-forward service/gateway 8080:8000`\n",
      "\n",
      "The Kasten dashboard will be available at: `http://127.0.0.1:8080/k10/#/`\n"
     ]
    }
   ],
   "source": [
    "#reinstall Kasten\n",
    "kubectl create ns kasten-io\n",
    "helm install k10 kasten/k10 --namespace=kasten-io --set global.persistence.storageClass=vsphere-csi "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddd362f",
   "metadata": {},
   "source": [
    "#### create location profile (in my case my Azure Blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "d1b3252b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile.config.kio.kasten.io/az-stephan created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "apiVersion: config.kio.kasten.io/v1alpha1\n",
    "kind: Profile\n",
    "metadata:\n",
    "  name: az-stephan\n",
    "  namespace: kasten-io\n",
    "spec:\n",
    "  locationSpec:\n",
    "    credential:\n",
    "      secret:\n",
    "        apiVersion: v1\n",
    "        kind: secret\n",
    "        name: k10secret-dm9zg\n",
    "        namespace: kasten-io\n",
    "      secretType: AzStorageAccount\n",
    "    objectStore:\n",
    "      name: kasten-demo\n",
    "      objectStoreType: AZ\n",
    "      path: k10/893bbee8-f8d3-4d89-a908-e105f893ad58/migration\n",
    "      pathType: Directory\n",
    "      region: West Europe\n",
    "    type: ObjectStore\n",
    "  type: Location\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "9a8fe054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/k10secret-dm9zg created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "apiVersion: v1\n",
    "data:\n",
    "  azure_storage_account_id: Y3Rja2FzdGVu\n",
    "  azure_storage_key: d2p5RmsvZkRTMldrYUd3ZjhERUF2S2Q1L1ZsRjZIcXdLb2lHYWFIYjFtdWpLSTU1Sm1JaXRoMzFwWjVLejFmc2hsaFlRTEVCZld5ZWw4ejdBTmd5NHc9PQ==\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: k10secret-dm9zg\n",
    "  namespace: kasten-io\n",
    "type: Opaque\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "5ab651c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/k10-dr-secret created\n"
     ]
    }
   ],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "apiVersion: v1\n",
    "data:\n",
    "  key: a2FzdGVuMXNjODhs\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: k10-dr-secret\n",
    "  namespace: kasten-io\n",
    "type: Opaque\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "e23a17ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile.config.kio.kasten.io/vsphere-ctc created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cat << 'EOF' | kubectl apply -f -\n",
    "apiVersion: config.kio.kasten.io/v1alpha1\n",
    "kind: Profile\n",
    "metadata:\n",
    "  name: vsphere-ctc\n",
    "  namespace: kasten-io\n",
    "spec:\n",
    "  infra:\n",
    "    credential:\n",
    "      secret:\n",
    "        apiVersion: v1\n",
    "        kind: secret\n",
    "        name: k10secret-tblw6\n",
    "        namespace: kasten-io\n",
    "      secretType: VSphereKey\n",
    "    type: VSphere\n",
    "    vsphere:\n",
    "      serverAddress: vc.container.demo.local\n",
    "  type: Infra\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbaeb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat << 'EOF' | kubectl apply -f -\n",
    "apiVersion: v1\n",
    "data:\n",
    "  vsphere_password: UmF0aW5nZW4uMTIz\n",
    "  vsphere_user: c2tvY2hAZGVtby5sb2NhbA==\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: k10secret-tblw6\n",
    "  namespace: kasten-io\n",
    "type: Opaque\n",
    "\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167e689",
   "metadata": {},
   "source": [
    "### change clusterID from above !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "54a0802c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: k10-restore\n",
      "LAST DEPLOYED: Wed Apr  7 15:34:07 2021\n",
      "NAMESPACE: kasten-io\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n"
     ]
    }
   ],
   "source": [
    " #Install the helm chart that creates the K10 restore job and wait for completion of the `k10-restore` job\n",
    " #Assumes that K10 is installed in 'kasten-io' namespace.\n",
    " helm install k10-restore kasten/k10restore  \\\n",
    "    --set sourceClusterID=93212760-78fe-4b02-aee0-34ac59e46048 \\\n",
    "    --set profile.name=az-stephan \\\n",
    "    --set global.persistence.storageClass=vsphere-csi \\\n",
    "    --set skipResource=\"profiles\" \\\n",
    "    --namespace=kasten-io \n",
    "    \n",
    "#--set skipResource=\"profiles\\,policies\" \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012d2a6c",
   "metadata": {},
   "source": [
    "![RestoreInProg](pictures/Restore-K10-inprog.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "bb78c12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context \"default\" modified.\n",
      "Active namespace is \"kasten-io\".\n",
      "NAME                                  READY   STATUS      RESTARTS   AGE\n",
      "aggregatedapis-svc-5cf667dbb8-gtzfn   1/1     Running     0          167m\n",
      "dashboardbff-svc-66787557b5-fbvxx     1/1     Running     0          167m\n",
      "auth-svc-54546c78ff-6bbbg             1/1     Running     0          167m\n",
      "state-svc-5588b7845c-lrm9x            1/1     Running     0          167m\n",
      "jobs-svc-76fc88c449-h4vgs             1/1     Running     0          167m\n",
      "frontend-svc-784d5fb99c-rflzb         1/1     Running     0          167m\n",
      "metering-svc-67fd96b56b-jxxbj         1/1     Running     0          167m\n",
      "kanister-svc-8576d8bdfb-7fnct         1/1     Running     0          167m\n",
      "executor-svc-6b8f7ff6-h2vr5           2/2     Running     0          167m\n",
      "logging-svc-5d4bcc7f9d-x7rhv          1/1     Running     0          167m\n",
      "executor-svc-6b8f7ff6-7fz7x           2/2     Running     0          167m\n",
      "executor-svc-6b8f7ff6-ctx67           2/2     Running     0          167m\n",
      "prometheus-server-78b94b85fb-zp4hd    2/2     Running     0          167m\n",
      "gateway-7f9b6b47b-mfg9m               1/1     Running     0          167m\n",
      "catalog-svc-695d858f9-l97ph           2/2     Running     0          12m\n",
      "crypto-svc-66b8cbf669-gn6sj           1/1     Running     0          11m\n",
      "config-svc-6dd78f5cd5-nvzqj           1/1     Running     0          11m\n",
      "k10-restore-k10restore-sjn7g          0/1     Completed   0          13m\n",
      "NAME       \tNAMESPACE\tREVISION\tUPDATED                                \tSTATUS  \tCHART            \tAPP VERSION\n",
      "k10        \tkasten-io\t1       \t2021-04-07 08:47:07.973176597 +0000 UTC\tdeployed\tk10-3.0.10       \t3.0.10     \n",
      "k10-restore\tkasten-io\t1       \t2021-04-07 11:21:10.579186391 +0000 UTC\tdeployed\tk10restore-3.0.10\t3.0.10     \n"
     ]
    }
   ],
   "source": [
    "kubens kasten-io\n",
    "kubectl get pod\n",
    "helm list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562225a",
   "metadata": {},
   "source": [
    "#### recreate Infra Provider and then all your Applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
